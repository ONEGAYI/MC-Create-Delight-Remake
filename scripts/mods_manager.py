import os
import sqlite3
import hashlib
import argparse
import sys
import re
import shutil
from datetime import datetime
from pathlib import Path

# ================= é…ç½®åŒºåŸŸ =================
script_dir = os.path.dirname(os.path.abspath(__file__))
os.chdir(script_dir)  # åˆ‡æ¢å·¥ä½œç›®å½•åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•
# æ•°æ®åº“æ–‡ä»¶å
DB_NAME = '../docs/mods_metadata.db'
# é»˜è®¤æ‰«æçš„æ–‡ä»¶å¤¹è·¯å¾„ (ä½ å¯ä»¥ä¿®æ”¹è¿™é‡Œï¼Œæˆ–è€…è¿è¡Œæ—¶æŒ‡å®š)
DEFAULT_FOLDER = '..\\mods'

# æ ¸å¿ƒè¡¨ç»“æ„ï¼šå¿…é¡»åŒ…å« sha å’Œ filenameï¼Œå…¶ä»–å­—æ®µä½ å¯ä»¥åŠ¨æ€æ·»åŠ 
# è¿™é‡Œçš„ keys å¯¹åº”æ•°æ®åº“åˆ—åï¼Œvalues æ˜¯ç±»å‹
CORE_FIELDS = {
    'sha': 'TEXT PRIMARY KEY',
    'filename': 'TEXT',
    'filepath': 'TEXT',
    'created_at': 'TIMESTAMP'
}
# ===========================================

class AssetManager:
    def __init__(self, db_path, folder_path):
        self.db_path = db_path
        self.folder_path = folder_path
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row  # è®©æŸ¥è¯¢ç»“æœåƒå­—å…¸ä¸€æ ·è®¿é—®
        self.cursor = self.conn.cursor()
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        fields_sql = ", ".join([f"{k} {v}" for k, v in CORE_FIELDS.items()])
        create_table_sql = f"CREATE TABLE IF NOT EXISTS files ({fields_sql})"
        self.cursor.execute(create_table_sql)
        self.conn.commit()

    def get_file_sha256(self, filepath):
        """è®¡ç®—æ–‡ä»¶çš„ SHA256 å“ˆå¸Œå€¼ (æµå¼è¯»å–ï¼Œé˜²å†…å­˜æº¢å‡º)"""
        sha256_hash = hashlib.sha256()
        try:
            with open(filepath, "rb") as f:
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            return sha256_hash.hexdigest()
        except Exception as e:
            print(f"Error reading {filepath}: {e}")
            return None

    def add_custom_field(self, field_name, field_type='TEXT'):
        """
        [åŠŸèƒ½ 1] åŠ¨æ€æ·»åŠ å­—æ®µ
        ç”¨æˆ·å¸Œæœ›è‡ªå·±æ·»åŠ ä¿¡æ¯å­—æ®µã€‚
        """
        try:
            self.cursor.execute(f"ALTER TABLE files ADD COLUMN {field_name} {field_type}")
            self.conn.commit()
            print(f"âœ… æˆåŠŸæ·»åŠ å­—æ®µ: {field_name} ({field_type})")
        except sqlite3.OperationalError as e:
            if "duplicate column name" in str(e):
                print(f"âš ï¸ å­—æ®µ {field_name} å·²å­˜åœ¨ã€‚")
            else:
                print(f"âŒ æ·»åŠ å­—æ®µå¤±è´¥: {e}")

    def sync_folder(self, auto_confirm=False):
        """
        [åŠŸèƒ½ 2] æ–‡ä»¶å¤¹æ›´æ–°æ£€æŸ¥
        - è¯†åˆ«æ–°å¢
        - è¯†åˆ«å‡å°‘ (éœ€ç¡®è®¤)
        - æ›´æ–°æ–‡ä»¶å (å¦‚æœå†…å®¹æ²¡å˜ä½†æ”¹åäº†)
        """
        if not os.path.exists(self.folder_path):
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {self.folder_path}")
            return

        print(f"ğŸ” æ­£åœ¨æ‰«ææ–‡ä»¶å¤¹: {self.folder_path} ...")
        
        # 1. è·å–ç£ç›˜ä¸Šçš„ç°çŠ¶ï¼ˆåªæ‰«æç¬¬ä¸€å±‚ï¼Œä¸é€’å½’å­æ–‡ä»¶å¤¹ï¼‰
        disk_files = {} # {sha: {filepath, filename}}
        for file in os.listdir(self.folder_path):
            # è·³è¿‡éšè—æ–‡ä»¶
            if file.startswith('.'): continue  # éšè—æ–‡ä»¶
            path = os.path.join(self.folder_path, file)
            # åªå¤„ç†æ–‡ä»¶ï¼Œè·³è¿‡å­æ–‡ä»¶å¤¹
            if not os.path.isfile(path): continue
            sha = self.get_file_sha256(path)
            if sha:
                disk_files[sha] = {'path': path, 'name': file}

        # 2. è·å–æ•°æ®åº“ç°çŠ¶
        self.cursor.execute("SELECT sha, filename, filepath FROM files")
        db_rows = self.cursor.fetchall()
        db_shas = {row['sha']: row for row in db_rows}

        disk_sha_set = set(disk_files.keys())
        db_sha_set = set(db_shas.keys())

        # 3. æ¯”è¾ƒå·®å¼‚
        added_shas = disk_sha_set - db_sha_set
        removed_shas = db_sha_set - disk_sha_set
        common_shas = disk_sha_set & db_sha_set

        # å¤„ç†æ–°å¢
        if added_shas:
            print(f"\nğŸŸ¢ å‘ç° {len(added_shas)} ä¸ªæ–°æ–‡ä»¶:")
            for sha in added_shas:
                info = disk_files[sha]
                print(f"   + {info['name']}")
                # å†™å…¥æ•°æ®åº“
                self.cursor.execute(
                    "INSERT INTO files (sha, filename, filepath, created_at) VALUES (?, ?, ?, ?)",
                    (sha, info['name'], info['path'], datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
                )
            self.conn.commit()
            print("âœ… æ–°å¢æ–‡ä»¶å·²å½•å…¥æ•°æ®åº“ã€‚")
        else:
            print("\nâšª æ²¡æœ‰æ£€æµ‹åˆ°æ–°æ–‡ä»¶ã€‚")

        # å¤„ç†ç§»åŠ¨/é‡å‘½å (åœ¨ common_shas ä¸­æ£€æŸ¥è·¯å¾„æ˜¯å¦å˜åŒ–)
        updated_count = 0
        for sha in common_shas:
            new_path = disk_files[sha]['path']
            new_name = disk_files[sha]['name']
            old_path = db_shas[sha]['filepath']
            
            if new_path != old_path:
                self.cursor.execute(
                    "UPDATE files SET filepath = ?, filename = ? WHERE sha = ?",
                    (new_path, new_name, sha)
                )
                updated_count += 1
        if updated_count > 0:
            self.conn.commit()
            print(f"ğŸ”µ æ›´æ–°äº† {updated_count} ä¸ªæ–‡ä»¶çš„è·¯å¾„/åç§°ä¿¡æ¯ã€‚")

        # å¤„ç†åˆ é™¤ (éœ€è¦ç”¨æˆ·ç¡®è®¤)
        if removed_shas:
            print(f"\nğŸ”´ æ•°æ®åº“ä¸­æœ‰ {len(removed_shas)} ä¸ªæ–‡ä»¶åœ¨æœ¬åœ°æ–‡ä»¶å¤¹æ‰¾ä¸åˆ°:")
            for sha in removed_shas:
                print(f"   - {db_shas[sha]['filename']} (SHA: {sha[:8]}...)")
            
            if auto_confirm:
                print("\nğŸ”§ è‡ªåŠ¨ç¡®è®¤æ¨¡å¼ï¼šåˆ é™¤ç¼ºå¤±æ–‡ä»¶çš„æ•°æ®åº“è®°å½•ã€‚")
                confirm = 'yes'
            else:
                confirm = input("\nâš ï¸ æ˜¯å¦ä»æ•°æ®åº“ä¸­åˆ é™¤è¿™äº›è®°å½•? (è¾“å…¥ 'yes' ç¡®è®¤): ")
            if confirm.lower() == 'yes':
                for sha in removed_shas:
                    self.cursor.execute("DELETE FROM files WHERE sha = ?", (sha,))
                self.conn.commit()
                print("âœ… è®°å½•å·²åˆ é™¤ã€‚")
            else:
                print("ğŸš« æ“ä½œå–æ¶ˆï¼Œæ•°æ®åº“ä¿æŒåŸæ ·ã€‚")
        else:
            print("âšª æ²¡æœ‰æ£€æµ‹åˆ°æ–‡ä»¶ä¸¢å¤±ã€‚")

    def list_missing_fields(self, field):
        """
        [åŠŸèƒ½ 3] å±•ç¤ºå­—æ®µç¼ºå¤±çš„é¡¹
        """
        try:
            # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
            self.cursor.execute("SELECT * FROM files LIMIT 0")
            col_names = [description[0] for description in self.cursor.description]
            if field not in col_names:
                print(f"âŒ æ•°æ®åº“ä¸­ä¸å­˜åœ¨å­—æ®µ: {field}")
                return

            # è·å–æ€»æ•°
            self.cursor.execute("SELECT COUNT(*) as total FROM files")
            total_count = self.cursor.fetchone()['total']

            # è·å–ç¼ºå¤±é¡¹
            sql = f"SELECT sha, filename FROM files WHERE {field} IS NULL OR {field} = ''"
            self.cursor.execute(sql)
            rows = self.cursor.fetchall()

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            missing_count = len(rows)
            passed_count = total_count - missing_count

            print(f"æ£€æŸ¥äº† '{field}' å­—æ®µï¼Œé€šè¿‡æ£€æŸ¥çš„æœ‰: {passed_count} / {total_count}")

            if not rows:
                print(f"âœ¨ æ‰€æœ‰æ–‡ä»¶çš„ '{field}' å­—æ®µéƒ½å·²å¡«å†™å®Œæ•´ï¼")
            else:
                print(f"\nğŸŸ  å…±æœ‰ {missing_count} ä¸ªæ–‡ä»¶ç¼ºå¤± '{field}':")
                for row in rows:
                    print(f"   [SHA: {row['sha'][:8]}] {row['filename']}")
        except Exception as e:
            print(f"Error: {e}")

    def update_single_item(self, sha_prefix, field, value):
        """
        [åŠŸèƒ½ 3] å¡«å…¥æ¥å£ (å•ä¸ª)
        """
        # æ¨¡ç³ŠåŒ¹é… SHA
        self.cursor.execute("SELECT sha, filename FROM files WHERE sha LIKE ?", (sha_prefix + '%',))
        rows = self.cursor.fetchall()
        
        if len(rows) == 0:
            print("âŒ æ‰¾ä¸åˆ°å¯¹åº”çš„ SHAã€‚")
            return
        elif len(rows) > 1:
            print("âŒ SHA å‰ç¼€ä¸å”¯ä¸€ï¼ŒåŒ¹é…åˆ°å¤šä¸ªæ–‡ä»¶ã€‚è¯·æä¾›æ›´é•¿çš„ SHAã€‚")
            return
        
        target_sha = rows[0]['sha']
        filename = rows[0]['filename']

        try:
            self.cursor.execute(f"UPDATE files SET {field} = ? WHERE sha = ?", (value, target_sha))
            self.conn.commit()
            print(f"âœ… å·²æ›´æ–° [{filename}] çš„ {field} = {value}")
        except Exception as e:
            print(f"âŒ æ›´æ–°å¤±è´¥: {e}")

    def batch_update(self, field, value, filter_sql=None):
        """
        [åŠŸèƒ½ 4] å¤§è§„æ¨¡å¯¹é¡¹è¿›è¡ŒæŸä¸€å­—æ®µçš„å†™
        filter_sql: å¯é€‰çš„ WHERE å­å¥ï¼Œç”¨äºé™å®šèŒƒå›´
        """
        print(f"\nâš ï¸ å‡†å¤‡å°†æ‰€æœ‰è®°å½•çš„ '{field}' å­—æ®µä¿®æ”¹ä¸º '{value}'")
        if filter_sql:
            print(f"   è¿‡æ»¤æ¡ä»¶: {filter_sql}")
        
        confirm = input("æ­¤æ“ä½œå°†å½±å“å¤§é‡æ•°æ®ï¼Œç¡®è®¤æ‰§è¡Œå—? (è¾“å…¥ 'yes' ç¡®è®¤): ")
        if confirm.lower() != 'yes':
            print("ğŸš« æ“ä½œå–æ¶ˆã€‚")
            return

        try:
            sql = f"UPDATE files SET {field} = ?"
            if filter_sql:
                sql += f" WHERE {filter_sql}"
            
            self.cursor.execute(sql, (value,))
            self.conn.commit()
            print(f"âœ… æˆåŠŸæ›´æ–°äº† {self.cursor.rowcount} æ¡è®°å½•ã€‚")
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ›´æ–°å¤±è´¥: {e}")
            print("æç¤º: ç¡®ä¿å­—æ®µå­˜åœ¨ã€‚å¦‚æœæ˜¯æ–°å­—æ®µï¼Œè¯·å…ˆä½¿ç”¨ 'add_field' å‘½ä»¤ã€‚")

    def show_columns(self):
        self.cursor.execute("PRAGMA table_info(files)")
        columns = self.cursor.fetchall()
        print("\nğŸ“Š å½“å‰æ•°æ®åº“å­—æ®µ:")
        for col in columns:
            print(f"   - {col[1]} ({col[2]})")

    def delete_field(self, field_name):
        """
        [åŠŸèƒ½ 5] åˆ é™¤æ•°æ®åº“å­—æ®µ
        æ³¨æ„ï¼šSQLiteä¸æ”¯æŒç›´æ¥åˆ é™¤å­—æ®µï¼Œéœ€è¦é‡å»ºè¡¨
        """
        try:
            # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
            self.cursor.execute("PRAGMA table_info(files)")
            columns = self.cursor.fetchall()
            col_names = [col[1] for col in columns]

            if field_name not in col_names:
                print(f"âŒ å­—æ®µ '{field_name}' ä¸å­˜åœ¨")
                return

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ ¸å¿ƒå­—æ®µï¼ˆä¸å…è®¸åˆ é™¤ï¼‰
            if field_name in CORE_FIELDS:
                print(f"âŒ ä¸èƒ½åˆ é™¤æ ¸å¿ƒå­—æ®µ '{field_name}'")
                return

            print(f"\nâš ï¸ å‡†å¤‡åˆ é™¤å­—æ®µ: {field_name}")
            confirm = input("æ­¤æ“ä½œå°†é‡å»ºæ•°æ®åº“è¡¨ï¼Œç¡®è®¤æ‰§è¡Œå—? (è¾“å…¥ 'yes' ç¡®è®¤): ")
            if confirm.lower() != 'yes':
                print("ğŸš« æ“ä½œå–æ¶ˆã€‚")
                return

            # è·å–å½“å‰è¡¨çš„æ‰€æœ‰æ•°æ®
            self.cursor.execute(f"SELECT * FROM files")
            rows = self.cursor.fetchall()

            # è·å–é™¤äº†è¦åˆ é™¤åˆ—ä¹‹å¤–çš„æ‰€æœ‰åˆ—å
            other_columns = [col for col in col_names if col != field_name]
            other_columns_str = ", ".join(other_columns)

            # åˆ›å»ºä¸´æ—¶è¡¨
            temp_table_sql = f"CREATE TABLE temp_files AS SELECT {other_columns_str} FROM files"
            self.cursor.execute(temp_table_sql)

            # åˆ é™¤åŸè¡¨
            self.cursor.execute("DROP TABLE files")

            # é‡æ–°åˆ›å»ºè¡¨ï¼ˆå»æ‰è¦åˆ é™¤çš„åˆ—ï¼‰
            fields_sql = ", ".join([f"{k} {v}" for k, v in CORE_FIELDS.items() if k != field_name])
            # æ·»åŠ å…¶ä»–éæ ¸å¿ƒå­—æ®µ
            for col_name in other_columns:
                if col_name not in CORE_FIELDS:
                    # è·å–åˆ—ç±»å‹
                    for col in columns:
                        if col[1] == col_name:
                            fields_sql += f", {col_name} {col[2]}"
                            break

            create_table_sql = f"CREATE TABLE files ({fields_sql})"
            self.cursor.execute(create_table_sql)

            # ä»ä¸´æ—¶è¡¨å¤åˆ¶æ•°æ®å›æ¥
            if other_columns:
                insert_sql = f"INSERT INTO files ({other_columns_str}) SELECT {other_columns_str} FROM temp_files"
                self.cursor.execute(insert_sql)

            # åˆ é™¤ä¸´æ—¶è¡¨
            self.cursor.execute("DROP TABLE temp_files")

            self.conn.commit()
            print(f"âœ… æˆåŠŸåˆ é™¤å­—æ®µ: {field_name}")

        except Exception as e:
            print(f"âŒ åˆ é™¤å­—æ®µå¤±è´¥: {e}")
            self.conn.rollback()

    def rename_field(self, old_name, new_name):
        """
        [åŠŸèƒ½ 6] é‡å‘½åå­—æ®µ
        æ³¨æ„ï¼šSQLite 3.25.0+æ”¯æŒç›´æ¥é‡å‘½åï¼Œè¿™é‡Œä½¿ç”¨å…¼å®¹æ€§æ›´å¥½çš„é‡å»ºè¡¨æ–¹æ³•
        """
        try:
            # æ£€æŸ¥æ—§å­—æ®µæ˜¯å¦å­˜åœ¨
            self.cursor.execute("PRAGMA table_info(files)")
            columns = self.cursor.fetchall()
            col_names = [col[1] for col in columns]

            if old_name not in col_names:
                print(f"âŒ å­—æ®µ '{old_name}' ä¸å­˜åœ¨")
                return

            if new_name in col_names:
                print(f"âŒ å­—æ®µ '{new_name}' å·²å­˜åœ¨")
                return

            print(f"\nâš ï¸ å‡†å¤‡é‡å‘½åå­—æ®µ: {old_name} -> {new_name}")
            confirm = input("æ­¤æ“ä½œå°†é‡å»ºæ•°æ®åº“è¡¨ï¼Œç¡®è®¤æ‰§è¡Œå—? (è¾“å…¥ 'yes' ç¡®è®¤): ")
            if confirm.lower() != 'yes':
                print("ğŸš« æ“ä½œå–æ¶ˆã€‚")
                return

            # è·å–å½“å‰è¡¨çš„æ‰€æœ‰æ•°æ®
            self.cursor.execute(f"SELECT * FROM files")
            rows = self.cursor.fetchall()

            # åˆ›å»ºæ–°çš„åˆ—ååˆ—è¡¨ï¼ˆæ›¿æ¢æ—§åç§°ä¸ºæ–°åç§°ï¼‰
            new_columns = [new_name if col == old_name else col for col in col_names]
            new_columns_str = ", ".join(new_columns)
            old_columns_str = ", ".join(col_names)

            # åˆ›å»ºä¸´æ—¶è¡¨ï¼ˆä½¿ç”¨æ–°çš„åˆ—åï¼‰
            temp_table_sql = f"CREATE TABLE temp_files ({new_columns_str})"
            self.cursor.execute(temp_table_sql)

            # å¤åˆ¶æ•°æ®åˆ°ä¸´æ—¶è¡¨
            if rows:
                # æ„å»ºINSERTè¯­å¥ï¼Œå°†æ—§åˆ—åæ˜ å°„åˆ°æ–°åˆ—å
                insert_cols = ", ".join([f'"{col}"' for col in new_columns])
                select_cols = ", ".join([f'"{old_col}"' for old_col in col_names])
                insert_sql = f"INSERT INTO temp_files ({insert_cols}) SELECT {select_cols} FROM files"
                self.cursor.execute(insert_sql)

            # åˆ é™¤åŸè¡¨
            self.cursor.execute("DROP TABLE files")

            # é‡æ–°åˆ›å»ºè¡¨ï¼ˆä½¿ç”¨æ–°çš„åˆ—åå’Œç±»å‹ï¼‰
            fields_sql = []
            for col in columns:
                col_name = new_name if col[1] == old_name else col[1]
                fields_sql.append(f"{col_name} {col[2]}")

            create_table_sql = f"CREATE TABLE files ({', '.join(fields_sql)})"
            self.cursor.execute(create_table_sql)

            # ä»ä¸´æ—¶è¡¨å¤åˆ¶æ•°æ®å›æ¥
            if rows:
                insert_sql = f"INSERT INTO files ({new_columns_str}) SELECT {new_columns_str} FROM temp_files"
                self.cursor.execute(insert_sql)

            # åˆ é™¤ä¸´æ—¶è¡¨
            self.cursor.execute("DROP TABLE temp_files")

            self.conn.commit()
            print(f"âœ… æˆåŠŸé‡å‘½åå­—æ®µ: {old_name} -> {new_name}")

        except Exception as e:
            print(f"âŒ é‡å‘½åå­—æ®µå¤±è´¥: {e}")
            self.conn.rollback()

    def search_items(self, field, target, use_regex=False):
        """
        [åŠŸèƒ½ 7] æœç´¢æ•°æ®åº“ä¸­çš„é¡¹
        field: è¦æœç´¢çš„å­—æ®µå
        target: æœç´¢ç›®æ ‡å€¼
        use_regex: æ˜¯å¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
        """
        try:
            # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
            self.cursor.execute("PRAGMA table_info(files)")
            columns = self.cursor.fetchall()
            col_names = [col[1] for col in columns]

            if field not in col_names:
                print(f"âŒ å­—æ®µ '{field}' ä¸å­˜åœ¨")
                print(f"\nå¯ç”¨å­—æ®µ: {', '.join(col_names)}")
                return

            # æ„å»ºSQLæŸ¥è¯¢
            if use_regex:
                # ä½¿ç”¨SQLiteçš„REGEXPå‡½æ•°
                self.cursor.execute(f"SELECT sha, filename, {field}, filepath FROM files WHERE {field} IS NOT NULL AND {field} != ''")
                all_rows = self.cursor.fetchall()

                pattern = re.compile(target, re.IGNORECASE if not target.isupper() else 0)
                matched_rows = []

                for row in all_rows:
                    field_value = str(row[2]) if row[2] is not None else ""
                    if pattern.search(field_value):
                        matched_rows.append(row)

                matched_count = len(matched_rows)
            else:
                # ä½¿ç”¨LIKEè¿›è¡Œæ¨¡ç³ŠåŒ¹é…
                if target.startswith("'") and target.endswith("'"):
                    # å¦‚æœç”¨å¼•å·åŒ…å›´ï¼Œè¿›è¡Œç²¾ç¡®åŒ¹é…
                    search_target = target.strip("'")
                    sql = f"SELECT sha, filename, {field}, filepath FROM files WHERE {field} = ?"
                    self.cursor.execute(sql, (search_target,))
                else:
                    # å¦åˆ™è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
                    search_target = f"%{target}%"
                    sql = f"SELECT sha, filename, {field}, filepath FROM files WHERE {field} IS NOT NULL AND {field} != '' AND {field} LIKE ?"
                    self.cursor.execute(sql, (search_target,))

                matched_rows = self.cursor.fetchall()
                matched_count = len(matched_rows)

            # æ˜¾ç¤ºç»“æœ
            if matched_count == 0:
                print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…é¡¹ (å­—æ®µ: {field}, æœç´¢å€¼: {target})")
                if use_regex:
                    print("ğŸ’¡ æç¤º: æ­£åˆ™è¡¨è¾¾å¼å¯èƒ½éœ€è¦è°ƒæ•´")
                else:
                    print("ğŸ’¡ æç¤º: å°è¯•ä½¿ç”¨æ›´ç®€å•çš„æœç´¢è¯æˆ–æ·»åŠ å¼•å·è¿›è¡Œç²¾ç¡®åŒ¹é…")
            else:
                mode = "æ­£åˆ™è¡¨è¾¾å¼" if use_regex else ("æ¨¡ç³Š" if not target.startswith("'") else "ç²¾ç¡®")
                print(f"\nğŸ” æœç´¢ç»“æœ (æ¨¡å¼: {mode}åŒ¹é…, å­—æ®µ: {field})")
                print(f"{'='*80}")
                print(f"å…±æ‰¾åˆ° {matched_count} ä¸ªåŒ¹é…é¡¹:")
                print(f"{'='*80}")

                for i, row in enumerate(matched_rows, 1):
                    sha = row['sha'][:12] + "..."
                    filename = row['filename']
                    field_value = str(row[field]) if row[field] is not None else "(ç©º)"
                    filepath = row['filepath']

                    print(f"\n{i:3d}. ã€{filename}ã€‘")
                    print(f"     SHA: {sha}")
                    print(f"     {field}: {field_value}")
                    # åªæ˜¾ç¤ºç›¸å¯¹è·¯å¾„ï¼Œå‡å°‘è¾“å‡ºé•¿åº¦
                    rel_path = filepath.replace(DEFAULT_FOLDER, ".") if filepath.startswith(DEFAULT_FOLDER) else filepath
                    print(f"     è·¯å¾„: {rel_path}")

                print(f"\n{'='*80}")
                print(f"æ€»è®¡: {matched_count} ä¸ªåŒ¹é…é¡¹")

        except re.error as e:
            print(f"âŒ æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {e}")
            print("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•")
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")

    def backup_database(self, backup_dir=None):
        """
        [åŠŸèƒ½ 8] å¤‡ä»½æ•°æ®åº“
        å°†å½“å‰æ•°æ®åº“å¤‡ä»½åˆ°æŒ‡å®šç›®å½•
        """
        try:
            # è·å–æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            db_abs_path = os.path.abspath(self.db_path)
            db_dir = os.path.dirname(db_abs_path)
            db_name = os.path.basename(db_abs_path).replace('.db', '')

            # ç¡®å®šå¤‡ä»½ç›®å½•
            if backup_dir is None:
                backup_dir = os.path.join(db_dir, 'bak')

            # åˆ›å»ºå¤‡ä»½ç›®å½•
            os.makedirs(backup_dir, exist_ok=True)

            # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_filename = f"{db_name}_{timestamp}.db"
            backup_path = os.path.join(backup_dir, backup_filename)

            # æ‰§è¡Œå¤‡ä»½
            shutil.copy2(db_abs_path, backup_path)

            print(f"âœ… æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")

            # åˆ—å‡ºæ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            backups = self.list_backups(backup_dir)
            print(f"ğŸ“ å½“å‰å…±æœ‰ {len(backups)} ä¸ªå¤‡ä»½æ–‡ä»¶")

            return backup_path

        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return None

    def list_backups(self, backup_dir=None):
        """
        åˆ—å‡ºæ‰€æœ‰å¤‡ä»½æ–‡ä»¶
        æŒ‰æ—¶é—´æˆ³æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        """
        try:
            # è·å–æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            db_abs_path = os.path.abspath(self.db_path)
            db_dir = os.path.dirname(db_abs_path)
            db_name = os.path.basename(db_abs_path).replace('.db', '')

            # ç¡®å®šå¤‡ä»½ç›®å½•
            if backup_dir is None:
                backup_dir = os.path.join(db_dir, 'bak')

            # å¦‚æœå¤‡ä»½ç›®å½•ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            if not os.path.exists(backup_dir):
                return []

            # æŸ¥æ‰¾æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            backups = []
            pattern = f"{db_name}_*.db"

            for filename in os.listdir(backup_dir):
                if filename.startswith(db_name + "_") and filename.endswith('.db'):
                    filepath = os.path.join(backup_dir, filename)
                    # æå–æ—¶é—´æˆ³
                    timestamp_part = filename[len(db_name)+1:-3]  # å»æ‰å‰ç¼€å’Œ.db
                    try:
                        # å°è¯•è§£ææ—¶é—´æˆ³
                        timestamp = datetime.strptime(timestamp_part, '%Y%m%d_%H%M%S')
                        backups.append({
                            'path': filepath,
                            'filename': filename,
                            'timestamp': timestamp,
                            'size': os.path.getsize(filepath)
                        })
                    except ValueError:
                        # å¦‚æœæ—¶é—´æˆ³æ ¼å¼ä¸å¯¹ï¼Œä»ç„¶ä¿ç•™ä½†æ’åœ¨åé¢
                        backups.append({
                            'path': filepath,
                            'filename': filename,
                            'timestamp': None,
                            'size': os.path.getsize(filepath)
                        })

            # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œæœ‰æ—¶é—´æˆ³çš„åœ¨å‰ï¼Œæ—¶é—´æˆ³è¶Šæ–°è¶Šå‰
            backups.sort(key=lambda x: (x['timestamp'] is None, x['timestamp']), reverse=True)

            return backups

        except Exception as e:
            print(f"âŒ åˆ—å‡ºå¤‡ä»½å¤±è´¥: {e}")
            return []

    def restore_database(self, backup_dir=None, backup_file=None):
        """
        [åŠŸèƒ½ 9] æ¢å¤æ•°æ®åº“
        ä»å¤‡ä»½æ–‡ä»¶æ¢å¤æ•°æ®åº“
        """
        try:
            # è·å–æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            db_abs_path = os.path.abspath(self.db_path)

            # ç¡®å®šå¤‡ä»½ç›®å½•
            if backup_dir is None:
                db_dir = os.path.dirname(db_abs_path)
                backup_dir = os.path.join(db_dir, 'bak')

            # å¦‚æœæ²¡æœ‰æŒ‡å®šå¤‡ä»½æ–‡ä»¶ï¼Œé€‰æ‹©æœ€æ–°çš„
            if backup_file is None:
                backups = self.list_backups(backup_dir)
                if not backups:
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„å¤‡ä»½æ–‡ä»¶")
                    return False

                backup_file = backups[0]['path']
                print(f"ğŸ“‹ è‡ªåŠ¨é€‰æ‹©æœ€æ–°å¤‡ä»½: {os.path.basename(backup_file)}")
            else:
                # å¦‚æœæ˜¯æ–‡ä»¶åï¼Œæ‹¼æ¥å®Œæ•´è·¯å¾„
                if not os.path.isabs(backup_file):
                    backup_file = os.path.join(backup_dir, backup_file)

                if not os.path.exists(backup_file):
                    print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
                    return False

            # å…³é—­å½“å‰æ•°æ®åº“è¿æ¥
            if self.conn:
                self.conn.close()
                self.conn = None

            # æ‰§è¡Œæ¢å¤
            shutil.copy2(backup_file, db_abs_path)

            # é‡æ–°å»ºç«‹æ•°æ®åº“è¿æ¥
            self.conn = sqlite3.connect(self.db_path)
            self.conn.row_factory = sqlite3.Row
            self.cursor = self.conn.cursor()

            print(f"âœ… æ•°æ®åº“å·²ä»å¤‡ä»½æ¢å¤: {backup_file}")

            # éªŒè¯æ¢å¤åçš„æ•°æ®åº“
            try:
                self.cursor.execute("SELECT COUNT(*) FROM files")
                count = self.cursor.fetchone()[0]
                print(f"ğŸ“Š æ¢å¤å®Œæˆï¼Œæ•°æ®åº“ä¸­å…±æœ‰ {count} æ¡è®°å½•")
            except:
                print("âš ï¸ è­¦å‘Šï¼šæ¢å¤åçš„æ•°æ®åº“å¯èƒ½æ²¡æœ‰æ–‡ä»¶è¡¨ï¼Œè¯·å…ˆè¿è¡Œ sync å‘½ä»¤")

            return True

        except Exception as e:
            print(f"âŒ æ¢å¤å¤±è´¥: {e}")
            # å°è¯•é‡æ–°å»ºç«‹è¿æ¥
            try:
                if not self.conn:
                    self.conn = sqlite3.connect(self.db_path)
                    self.conn.row_factory = sqlite3.Row
                    self.cursor = self.conn.cursor()
            except:
                pass
            return False

    def export_to_csv(self, output_path=None, table_name='files'):
        """
        [åŠŸèƒ½ 10] å¯¼å‡ºæ•°æ®åº“åˆ°CSVæ–‡ä»¶
        æ”¯æŒæŒ‡å®šè¡¨åå¯¼å‡ºï¼Œå…¼å®¹Excelæ‰“å¼€

        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: ../docs/mods_metadata.csvï¼‰
            table_name: è¦å¯¼å‡ºçš„è¡¨åï¼ˆé»˜è®¤: filesï¼‰
        """
        import csv
        import os

        try:
            # å‚æ•°å¤„ç†å’ŒéªŒè¯
            if output_path is None:
                output_path = '../docs/mods_metadata.csv'

            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            self.cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in self.cursor.fetchall()]
            if table_name not in tables:
                print(f"âŒ è¡¨ '{table_name}' ä¸å­˜åœ¨")
                print(f"å¯ç”¨è¡¨: {', '.join(tables)}")
                return False

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(os.path.abspath(output_path))
            os.makedirs(output_dir, exist_ok=True)

            # è·å–è¡¨çš„å­—æ®µä¿¡æ¯
            self.cursor.execute(f"PRAGMA table_info({table_name})")
            columns = self.cursor.fetchall()

            # æ„å»ºæŸ¥è¯¢è¯­å¥ - é’ˆå¯¹filesè¡¨çš„ç‰¹æ®Šå¤„ç†
            if table_name == 'files':
                query = """
                SELECT COALESCE(modname, '') as modname,
                       filename,
                       COALESCE(env, '') as env,
                       COALESCE(tags, '') as tags,
                       COALESCE(description, '') as description
                FROM files
                ORDER BY
                    CASE
                        WHEN modname IS NULL OR modname = '' THEN 2
                        ELSE 1
                    END,
                    modname,
                    filename
                """
                headers = ['æ¨¡ç»„å', 'æ–‡ä»¶å', 'ç¯å¢ƒ', 'æ ‡ç­¾', 'æè¿°']
            else:
                # é€šç”¨è¡¨å¤„ç†
                column_names = [col[1] for col in columns]
                headers = column_names
                query = f"SELECT * FROM {table_name}"

            # æ‰§è¡ŒæŸ¥è¯¢
            self.cursor.execute(query)
            rows = self.cursor.fetchall()

            if not rows:
                print(f"âŒ è¡¨ '{table_name}' ä¸­æ²¡æœ‰è®°å½•å¯å¯¼å‡º")
                return False

            # å†™å…¥CSVï¼ˆUTF-8 BOMç¼–ç ï¼‰
            with open(output_path, 'w', encoding='utf-8-sig', newline='') as csvfile:
                writer = csv.writer(csvfile, quoting=csv.QUOTE_MINIMAL)

                # å†™å…¥æ ‡é¢˜è¡Œ
                writer.writerow(headers)

                # å†™å…¥æ•°æ®è¡Œ
                for row in rows:
                    # è½¬æ¢æ•°æ®
                    if table_name == 'files':
                        # filesè¡¨çš„ç‰¹æ®Šå¤„ç†
                        modname = row[0] if row[0] else ''
                        filename = row[1] if row[1] else ''
                        env = row[2] if row[2] else ''
                        tags = row[3] if row[3] else ''
                        description = row[4] if row[4] else ''

                        # å¤„ç†åŒ…å«é€—å·çš„å­—æ®µ - ä½¿ç”¨åŒå¼•å·åŒ…å›´
                        data_row = [modname, filename, env, tags, description]
                        formatted_row = []

                        for value in data_row:
                            # å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²å†æ£€æŸ¥
                            value_str = str(value)
                            if value and (',' in value_str or '"' in value_str or '\n' in value_str):
                                # è½¬ä¹‰åŒå¼•å·å¹¶ç§»é™¤æ¢è¡Œç¬¦
                                value_str = value_str.replace('"', '""').replace('\n', ' ').replace('\r', '')
                                formatted_row.append(f'"{value_str}"')
                            else:
                                formatted_row.append(value_str)

                        writer.writerow(formatted_row)
                    else:
                        # é€šç”¨è¡¨å¤„ç†
                        data_row = list(row)
                        formatted_row = []

                        for value in data_row:
                            if value and (',' in str(value) or '"' in str(value) or '\n' in str(value)):
                                value = str(value).replace('"', '""').replace('\n', ' ').replace('\r', '')
                                formatted_row.append(f'"{value}"')
                            else:
                                formatted_row.append(value if value is not None else '')

                        writer.writerow(formatted_row)

            print(f"âœ… å·²å¯¼å‡ºè¡¨ '{table_name}' åˆ°: {output_path}")
            print(f"ğŸ“Š å¯¼å‡ºè®°å½•æ•°: {len(rows)}")

            return True

        except PermissionError:
            print(f"âŒ æƒé™é”™è¯¯: æ— æ³•å†™å…¥æ–‡ä»¶ {output_path}")
            return False
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def show_by_sha(self, sha_prefix):
        """
        [åŠŸèƒ½ 11] æ ¹æ®SHAå‰ç¼€æ˜¾ç¤ºå®Œæ•´ä¿¡æ¯
        sha_prefix: SHAå‰ç¼€ï¼ˆè‡³å°‘12ä½ï¼‰
        """
        try:
            # éªŒè¯SHAé•¿åº¦
            if len(sha_prefix) < 12:
                print("âŒ SHAå‰ç¼€é•¿åº¦ä¸è¶³ï¼Œè¯·æä¾›è‡³å°‘12ä½SHA")
                return

            # æŸ¥è¯¢åŒ¹é…çš„è®°å½•
            self.cursor.execute("SELECT * FROM files WHERE sha LIKE ?", (sha_prefix + '%',))
            rows = self.cursor.fetchall()

            if len(rows) == 0:
                print(f"âŒ æ²¡æœ‰æ‰¾åˆ°SHAä»¥ '{sha_prefix}' å¼€å¤´çš„è®°å½•")
                return

            # è·å–æ‰€æœ‰å­—æ®µå
            self.cursor.execute("PRAGMA table_info(files)")
            columns = self.cursor.fetchall()
            col_names = [col[1] for col in columns]

            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ” æ‰¾åˆ° {len(rows)} ä¸ªåŒ¹é…é¡¹:")
            print(f"{'='*80}")

            for i, row in enumerate(rows, 1):
                filename = row['filename']
                print(f"\n{i}. ã€{filename}ã€‘")
                print(f"   SHA: {row['sha']}")

                # æ˜¾ç¤ºå…¶ä»–å­—æ®µï¼ˆæ’é™¤ sha å’Œ filenameï¼Œå› ä¸ºå·²ç»æ˜¾ç¤ºäº†ï¼‰
                for col in col_names:
                    if col not in ['sha', 'filename']:
                        value = row[col]
                        if value is not None and value != '':
                            print(f"   {col}: {value}")

            print(f"\n{'='*80}")
            print(f"æ€»è®¡: {len(rows)} ä¸ªåŒ¹é…é¡¹")

        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

# ================= å‘½ä»¤è¡Œæ¥å£é€»è¾‘ =================
def main():
    parser = argparse.ArgumentParser(
        description="æœ¬åœ°æ–‡ä»¶èµ„äº§ç®¡ç†è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
å‘½ä»¤åˆ†ç»„:
  æ•°æ®åŒæ­¥    sync            åŒæ­¥æ–‡ä»¶å¤¹å†…å®¹åˆ°æ•°æ®åº“

  å­—æ®µç®¡ç†    add_field       æ·»åŠ æ–°çš„ä¿¡æ¯å­—æ®µ
              delete_field    åˆ é™¤æŒ‡å®šçš„å­—æ®µ
              rename_field    é‡å‘½åæŒ‡å®šçš„å­—æ®µ
              info            æŸ¥çœ‹å½“å‰æ‰€æœ‰å­—æ®µ

  æ•°æ®ç¼–è¾‘    update          æ›´æ–°å•ä¸ªæ–‡ä»¶çš„å­—æ®µ
              batch_write     æ‰¹é‡å†™å…¥å­—æ®µ

  æ•°æ®æŸ¥è¯¢    search          æœç´¢æ•°æ®åº“ä¸­çš„é¡¹
              show            æ ¹æ®SHAå‰ç¼€æ˜¾ç¤ºå®Œæ•´ä¿¡æ¯

  æ•°æ®ç»´æŠ¤    check           æ£€æŸ¥æŸå­—æ®µç¼ºå¤±çš„é¡¹
              backup          æ•°æ®åº“å¤‡ä»½å’Œæ¢å¤
              export          å¯¼å‡ºæ•°æ®åº“åˆ°CSVæ–‡ä»¶
        """)
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # ========== æ•°æ®åŒæ­¥ ==========
    parser_sync = subparsers.add_parser('sync', help='åŒæ­¥æ–‡ä»¶å¤¹å†…å®¹åˆ°æ•°æ®åº“')
    parser_sync.add_argument('--folder', type=str, default=DEFAULT_FOLDER, help='æŒ‡å®šæ‰«ææ–‡ä»¶å¤¹è·¯å¾„')
    parser_sync.add_argument('--force', action='store_true', help='è‡ªåŠ¨ç¡®è®¤åˆ é™¤æ•°æ®åº“ä¸­ç¼ºå¤±æ–‡ä»¶çš„è®°å½•ï¼Œæ— éœ€ç”¨æˆ·ç¡®è®¤')

    # ========== å­—æ®µç®¡ç† ==========
    parser_add = subparsers.add_parser('add_field', help='æ·»åŠ æ–°çš„ä¿¡æ¯å­—æ®µ')
    parser_add.add_argument('name', type=str, help='å­—æ®µåç§° (è‹±æ–‡)')
    parser_add.add_argument('--type', type=str, default='TEXT', help='å­—æ®µç±»å‹ (TEXT, INTEGER, REAL)')

    parser_del = subparsers.add_parser('delete_field', help='åˆ é™¤æŒ‡å®šçš„å­—æ®µ')
    parser_del.add_argument('name', type=str, help='è¦åˆ é™¤çš„å­—æ®µå')

    parser_rename = subparsers.add_parser('rename_field', help='é‡å‘½åæŒ‡å®šçš„å­—æ®µ')
    parser_rename.add_argument('old_name', type=str, help='åŸå­—æ®µå')
    parser_rename.add_argument('new_name', type=str, help='æ–°å­—æ®µå')

    subparsers.add_parser('info', help='æŸ¥çœ‹å½“å‰æ‰€æœ‰å­—æ®µ')

    # ========== æ•°æ®ç¼–è¾‘ ==========
    parser_upd = subparsers.add_parser('update', help='æ›´æ–°å•ä¸ªæ–‡ä»¶çš„å­—æ®µ')
    parser_upd.add_argument('sha', type=str, help='æ–‡ä»¶ SHA å‰å‡ ä½')
    parser_upd.add_argument('field', type=str, help='å­—æ®µå')
    parser_upd.add_argument('value', type=str, help='å€¼')

    parser_batch = subparsers.add_parser('batch_write', help='æ‰¹é‡å†™å…¥å­—æ®µ')
    parser_batch.add_argument('field', type=str, help='å­—æ®µå')
    parser_batch.add_argument('value', type=str, help='å€¼')
    parser_batch.add_argument('--where', type=str, default=None, help='SQL WHERE æ¡ä»¶ (å¯é€‰ï¼Œä¾‹å¦‚ "author IS NULL")')

    # ========== æ•°æ®æŸ¥è¯¢ ==========
    parser_search = subparsers.add_parser('search', help='æœç´¢æ•°æ®åº“ä¸­çš„é¡¹')
    parser_search.add_argument('field', type=str, help='è¦æœç´¢çš„å­—æ®µå')
    parser_search.add_argument('target', type=str, help='æœç´¢ç›®æ ‡å€¼')
    parser_search.add_argument('-r', '--regex', action='store_true', help='ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼')

    parser_show = subparsers.add_parser('show', help='æ ¹æ®SHAå‰ç¼€æ˜¾ç¤ºå®Œæ•´ä¿¡æ¯')
    parser_show.add_argument('sha', type=str, help='SHAå‰ç¼€ï¼ˆè‡³å°‘12ä½ï¼‰')

    # ========== æ•°æ®ç»´æŠ¤ ==========
    parser_miss = subparsers.add_parser('check', help='æ£€æŸ¥æŸå­—æ®µç¼ºå¤±çš„é¡¹')
    parser_miss.add_argument('field', type=str, help='è¦æ£€æŸ¥çš„å­—æ®µå')

    parser_backup = subparsers.add_parser('backup', help='æ•°æ®åº“å¤‡ä»½å’Œæ¢å¤')
    backup_group = parser_backup.add_mutually_exclusive_group(required=True)
    backup_group.add_argument('-s', '--save', action='store_true', help='ä¿å­˜æ•°æ®åº“å¤‡ä»½')
    backup_group.add_argument('-l', '--load', action='store_true', help='ä»å¤‡ä»½æ¢å¤æ•°æ®åº“')
    parser_backup.add_argument('-d', '--dir', type=str, default=None, help='è‡ªå®šä¹‰å¤‡ä»½ç›®å½•è·¯å¾„')

    parser_export = subparsers.add_parser('export', help='å¯¼å‡ºæ•°æ®åº“åˆ°CSVæ–‡ä»¶')
    parser_export.add_argument('-d', '--dir', type=str,
                             default='../docs/mods_metadata.csv',
                             help='æŒ‡å®šå¯¼å‡ºè·¯å¾„ï¼ˆé»˜è®¤: docs/mods_metadata.csvï¼‰')
    parser_export.add_argument('-t', '--table', type=str, default='files',
                             help='æŒ‡å®šè¦å¯¼å‡ºçš„è¡¨åï¼ˆé»˜è®¤: filesï¼‰')

    args = parser.parse_args()

    # åˆå§‹åŒ–ç®¡ç†å™¨
    manager = AssetManager(DB_NAME, args.folder if hasattr(args, 'folder') else DEFAULT_FOLDER)

    if args.command == 'sync':
        manager.sync_folder(auto_confirm=args.force)
    elif args.command == 'add_field':
        manager.add_custom_field(args.name, args.type)
    elif args.command == 'check':
        manager.list_missing_fields(args.field)
    elif args.command == 'update':
        manager.update_single_item(args.sha, args.field, args.value)
    elif args.command == 'batch_write':
        manager.batch_update(args.field, args.value, args.where)
    elif args.command == 'info':
        manager.show_columns()
    elif args.command == 'delete_field':
        manager.delete_field(args.name)
    elif args.command == 'rename_field':
        manager.rename_field(args.old_name, args.new_name)
    elif args.command == 'search':
        manager.search_items(args.field, args.target, args.regex)
    elif args.command == 'backup':
        if args.save:
            # å¤‡ä»½æ•°æ®åº“
            backup_path = manager.backup_database(args.dir)
            if backup_path:
                # æ˜¾ç¤ºå¤‡ä»½åˆ—è¡¨
                backups = manager.list_backups(args.dir)
                if backups:
                    print("\nğŸ“‹ æ‰€æœ‰å¤‡ä»½æ–‡ä»¶:")
                    for i, backup in enumerate(backups[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                        timestamp_str = backup['timestamp'].strftime('%Y-%m-%d %H:%M:%S') if backup['timestamp'] else "æœªçŸ¥æ—¶é—´"
                        size_str = f"{backup['size']/1024:.1f} KB" if backup['size'] < 1024*1024 else f"{backup['size']/1024/1024:.1f} MB"
                        print(f"  {i}. {backup['filename']} - {timestamp_str} ({size_str})")
                    if len(backups) > 10:
                        print(f"  ... è¿˜æœ‰ {len(backups)-10} ä¸ªå¤‡ä»½")
        elif args.load:
            # æ¢å¤æ•°æ®åº“
            success = manager.restore_database(args.dir)
            if not success:
                print("âŒ æ¢å¤å¤±è´¥")
                sys.exit(1)
    elif args.command == 'export':
        manager.export_to_csv(
            output_path=args.dir,
            table_name=args.table
        )
    elif args.command == 'show':
        manager.show_by_sha(args.sha)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()