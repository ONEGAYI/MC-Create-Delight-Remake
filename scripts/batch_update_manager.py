#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
batch_update_manager.py
æ‰¹é‡æ›´æ–°æ•°æ®åº“ä¸­çš„æ¨¡ç»„ä¿¡æ¯

åŠŸèƒ½ï¼š
1. ä» updated_info.csv è¯»å–æ›´æ–°æ•°æ®
2. é€šè¿‡ SHA å‰ç¼€åŒ¹é…æ•°æ®åº“è®°å½•
3. æ‰¹é‡è°ƒç”¨ update_single_item æ–¹æ³•æ›´æ–°å­—æ®µ
4. æä¾›è¯¦ç»†çš„è¿›åº¦æ˜¾ç¤ºå’Œé”™è¯¯æŠ¥å‘Š
"""

import sys
import os
import csv
import argparse
import shutil
from datetime import datetime
from pathlib import Path
from io import StringIO
from contextlib import redirect_stdout

# æ·»åŠ è„šæœ¬ç›®å½•åˆ° Python è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(script_dir)

# å¯¼å…¥ç°æœ‰çš„ AssetManager
from mods_manager import AssetManager


class BatchUpdateManager:
    def __init__(self, db_path, csv_path):
        self.db_path = db_path
        self.csv_path = csv_path
        self.manager = None

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_records': 0,
            'successful_updates': 0,
            'failed_updates': 0,
            'not_found': 0,
            'invalid_fields': 0,
            'skipped': 0,
            'skipped_fields': 0  # è·³è¿‡çš„å­—æ®µæ•°
        }

        # é”™è¯¯è®°å½•
        self.error_records = []

        # å¯æ›´æ–°çš„å­—æ®µï¼ˆsha å’Œ filename ä»…ç”¨äºè¯†åˆ«ï¼Œä¸æ›´æ–°ï¼‰
        self.updatable_fields = {'env', 'tags', 'description', 'updated_at'}

        # ç‰¹æ®Šå ä½ç¬¦
        self.skip_placeholder = '<safely-jump>'

    def initialize(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        try:
            # åˆ›å»º AssetManager å®ä¾‹ï¼ˆä½¿ç”¨ dummy folder_pathï¼‰
            self.manager = AssetManager(self.db_path, "__dummy__")
            print(f"âœ“ æˆåŠŸåˆå§‹åŒ– AssetManager")
            return True
        except Exception as e:
            print(f"âœ— åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def read_csv_data(self):
        """è¯»å– CSV æ•°æ®"""
        csv_data = []

        try:
            with open(self.csv_path, 'r', encoding='utf-8-sig', newline='') as f:
                reader = csv.DictReader(f)

                # éªŒè¯å¿…è¦çš„åˆ—
                required_columns = ['sha', 'filename', 'env', 'tags', 'description']
                if not all(col in reader.fieldnames for col in required_columns):
                    missing = [col for col in required_columns if col not in reader.fieldnames]
                    print(f"âœ— CSV æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {missing}")
                    print(f"ç°æœ‰åˆ—: {reader.fieldnames}")
                    return None

                for row_num, row in enumerate(reader, 2):  # +2 å› ä¸ºæœ‰è¡¨å¤´è¡Œ
                    # è·³è¿‡ç©ºè¡Œæˆ–åªæœ‰ SHA çš„è¡Œ
                    sha = row.get('sha', '').strip()
                    if not sha:
                        self.stats['skipped'] += 1
                        self.error_records.append({
                            'type': 'missing_sha',
                            'row': row_num,
                            'filename': row.get('filename', 'N/A'),
                            'reason': 'SHA å€¼ä¸ºç©º'
                        })
                        continue

                    # æ¸…ç†æ•°æ®
                    updated_at = row.get('updated_at', '').strip()
                    # å¦‚æœ updated_at ä¸ºç©ºï¼Œåˆ™è‡ªåŠ¨å¡«å……å½“å‰æ—¶é—´æˆ³
                    if not updated_at:
                        updated_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

                    cleaned_row = {
                        'sha': sha,
                        'updated_at': updated_at,
                        'filename': row.get('filename', '').strip(),
                        'env': row.get('env', '').strip(),
                        'tags': row.get('tags', '').strip(),
                        'description': row.get('description', '').strip()
                    }

                    csv_data.append(cleaned_row)

            print(f"âœ“ æˆåŠŸè¯»å– CSVï¼Œå…± {len(csv_data)} æ¡è®°å½•")
            return csv_data

        except FileNotFoundError:
            print(f"âœ— CSV æ–‡ä»¶ä¸å­˜åœ¨: {self.csv_path}")
            return None
        except Exception as e:
            print(f"âœ— è¯»å– CSV å¤±è´¥: {e}")
            return None

    def backup_database(self):
        """å¤‡ä»½æ•°æ®åº“"""
        try:
            # ä½¿ç”¨ AssetManager çš„å¤‡ä»½åŠŸèƒ½
            backup_dir = Path(self.db_path).parent / 'backups'
            backup_dir.mkdir(exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_name = f"mods_metadata_backup_{timestamp}.db"
            backup_path = backup_dir / backup_name

            # å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
            shutil.copy2(self.db_path, backup_path)

            print(f"âœ“ æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")
            return backup_path

        except Exception as e:
            print(f"âš  å¤‡ä»½æ•°æ®åº“å¤±è´¥: {e}")
            return None

    def batch_update(self, csv_data, dry_run=False):
        """æ‰§è¡Œæ‰¹é‡æ›´æ–°"""
        self.stats['total_records'] = len(csv_data)

        print(f"\n{'[DRY RUN] ' if dry_run else ''}å¼€å§‹æ‰¹é‡æ›´æ–°...")
        print("-" * 80)

        for i, record in enumerate(csv_data, 1):
            # æ˜¾ç¤ºè¿›åº¦
            progress = f"\r[{i:3d}/{self.stats['total_records']:3d}]"
            filename = record.get('filename', 'Unknown')[:40]
            print(f"{progress} æ­£åœ¨å¤„ç†: {filename:<40}", end='', flush=True)

            # æ£€æŸ¥ SHA
            sha_prefix = record['sha']
            if not sha_prefix:
                self.stats['skipped'] += 1
                continue

            # è·å–éœ€è¦æ›´æ–°çš„å­—æ®µ
            updates = {}
            for field in self.updatable_fields:
                value = record.get(field, '').strip()
                if value == self.skip_placeholder:
                    # è·³è¿‡è¯¥å­—æ®µ
                    self.stats['skipped_fields'] += 1
                    continue
                elif value != '':
                    # éç©ºå­—æ®µï¼Œéœ€è¦æ›´æ–°
                    updates[field] = value
                else:
                    # ç©ºå­—ç¬¦ä¸²ï¼Œä¹Ÿè¦æ›´æ–°ï¼ˆç”¨æˆ·é€‰æ‹©ï¼‰
                    updates[field] = ''

            if not updates:
                self.stats['skipped'] += 1
                continue

            # æ‰§è¡Œæ›´æ–°
            success = True
            updated_fields = []

            for field, value in updates.items():
                if dry_run:
                    # å¹²è¿è¡Œæ¨¡å¼ï¼Œåªæ‰“å°ä¸æ‰§è¡Œ
                    if not any(err['field'] == field and err['sha_prefix'] == sha_prefix
                             for err in self.error_records if err.get('type') == 'dry_run'):
                        print(f"\n[DRY RUN] å°†æ›´æ–° {sha_prefix[:12]}... çš„ {field} = {value[:30] if len(str(value)) > 30 else value}")
                        self.error_records.append({
                            'type': 'dry_run',
                            'sha_prefix': sha_prefix,
                            'filename': record.get('filename', 'N/A'),
                            'field': field,
                            'value': str(value)[:50]
                        })
                else:
                    # è°ƒç”¨ AssetManager çš„ update_single_item æ–¹æ³•
                    try:
                        # ä¸´æ—¶é‡å®šå‘è¾“å‡ºä»¥æ•è·ç»“æœ
                        f = StringIO()
                        with redirect_stdout(f):
                            self.manager.update_single_item(sha_prefix, field, value)

                        output = f.getvalue()
                        if "âœ…" in output:
                            # æ›´æ–°æˆåŠŸ
                            updated_fields.append(field)
                        elif "æ‰¾ä¸åˆ°å¯¹åº”çš„ SHA" in output or "SHA å‰ç¼€ä¸å”¯ä¸€" in output:
                            self.stats['not_found'] += 1
                            self.error_records.append({
                                'type': 'sha_not_found',
                                'sha_prefix': sha_prefix,
                                'filename': record.get('filename', 'N/A'),
                                'field': field,
                                'error': output.strip()
                            })
                            success = False
                            break
                        else:
                            # å…¶ä»–é”™è¯¯
                            self.stats['failed_updates'] += 1
                            self.error_records.append({
                                'type': 'update_error',
                                'sha_prefix': sha_prefix,
                                'filename': record.get('filename', 'N/A'),
                                'field': field,
                                'error': output.strip()
                            })
                            success = False
                            break

                    except Exception as e:
                        self.stats['failed_updates'] += 1
                        self.error_records.append({
                            'type': 'exception',
                            'sha_prefix': sha_prefix,
                            'filename': record.get('filename', 'N/A'),
                            'field': field,
                            'error': str(e)
                        })
                        success = False
                        break

            if success and not dry_run and updated_fields:
                self.stats['successful_updates'] += 1
            elif not success and not dry_run:
                pass  # é”™è¯¯å·²åœ¨ä¸Šé¢è®°å½•

        print("\n" + "-" * 80)

    def generate_report(self):
        """ç”Ÿæˆæ›´æ–°æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("æ‰¹é‡æ›´æ–°ç»Ÿè®¡æŠ¥å‘Š")
        print("=" * 80)
        print(f"æ€»è®°å½•æ•°:          {self.stats['total_records']}")
        print(f"æˆåŠŸæ›´æ–°:          {self.stats['successful_updates']}")
        print(f"SHA æœªæ‰¾åˆ°:        {self.stats['not_found']}")
        print(f"æ›´æ–°å¤±è´¥:          {self.stats['failed_updates']}")
        print(f"è·³è¿‡è®°å½•:          {self.stats['skipped']}")
        print(f"è·³è¿‡å­—æ®µæ•°:        {self.stats['skipped_fields']}")

        if self.stats['total_records'] > 0:
            success_rate = self.stats['successful_updates'] / self.stats['total_records'] * 100
            print(f"æˆåŠŸç‡:            {success_rate:.1f}%")

        # æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
        if self.error_records:
            print("\n" + "-" * 80)
            print("é”™è¯¯è®°å½•è¯¦æƒ…")
            print("-" * 80)

            # è¿‡æ»¤æ‰å¹²è¿è¡Œè®°å½•
            error_records_filtered = [e for e in self.error_records if e.get('type') != 'dry_run']

            if not error_records_filtered:
                print("æ— é”™è¯¯è®°å½•")
            else:
                # æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„
                error_types = {}
                for error in error_records_filtered:
                    error_type = error['type']
                    if error_type not in error_types:
                        error_types[error_type] = []
                    error_types[error_type].append(error)

                # æ˜¾ç¤ºæ¯ç§é”™è¯¯çš„å‰å‡ æ¡
                for error_type, errors in error_types.items():
                    print(f"\n[{error_type}] ({len(errors)}ä¸ª):")
                    for error in errors[:5]:
                        if error_type == 'sha_not_found':
                            print(f"  SHA {error['sha_prefix'][:12]}... æœªæ‰¾åˆ° (æ–‡ä»¶: {error['filename']})")
                        elif error_type == 'update_error':
                            print(f"  {error['filename']}: {error['error'][:80]}...")
                        elif error_type == 'exception':
                            print(f"  {error['filename']}: {error['error'][:80]}...")
                        else:
                            print(f"  {error}")

                    if len(errors) > 5:
                        print(f"  ... è¿˜æœ‰ {len(errors) - 5} ä¸ªæœªæ˜¾ç¤º")

    def save_error_records(self):
        """ä¿å­˜é”™è¯¯è®°å½•åˆ°æ–‡ä»¶"""
        if not self.error_records:
            return

        # è¿‡æ»¤æ‰å¹²è¿è¡Œè®°å½•
        error_records_filtered = [e for e in self.error_records if e.get('type') != 'dry_run']

        if not error_records_filtered:
            return

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        error_log_path = Path(script_dir) / f'batch_update_errors_{timestamp}.log'

        try:
            with open(error_log_path, 'w', encoding='utf-8') as f:
                f.write(f"æ‰¹é‡æ›´æ–°é”™è¯¯æ—¥å¿— - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 80 + "\n\n")

                for error in error_records_filtered:
                    f.write(f"ç±»å‹: {error['type']}\n")
                    f.write(f"æ–‡ä»¶å: {error.get('filename', 'N/A')}\n")
                    if 'sha_prefix' in error:
                        f.write(f"SHA: {error['sha_prefix']}\n")
                    if 'field' in error:
                        f.write(f"å­—æ®µ: {error['field']}\n")
                    if 'error' in error:
                        f.write(f"é”™è¯¯: {error['error']}\n")
                    if 'reason' in error:
                        f.write(f"åŸå› : {error['reason']}\n")
                    if 'row' in error:
                        f.write(f"è¡Œå·: {error['row']}\n")
                    f.write("-" * 40 + "\n")

            print(f"\nâœ“ é”™è¯¯è®°å½•å·²ä¿å­˜åˆ°: {error_log_path}")

        except Exception as e:
            print(f"\nâš  ä¿å­˜é”™è¯¯è®°å½•å¤±è´¥: {e}")

    def show_preview(self, csv_data):
        """æ˜¾ç¤ºé¢„è§ˆæ•°æ®"""
        print("\næ•°æ®é¢„è§ˆ:")
        print("-" * 80)
        print(f"{'SHA':<12} {'æ–‡ä»¶å':<40} {'ç¯å¢ƒ':<10} {'æ ‡ç­¾':<20}")
        print("-" * 80)

        for record in csv_data[:5]:
            sha = record['sha'][:12] + "..." if len(record['sha']) > 12 else record['sha']
            filename = record['filename'][:37] + "..." if len(record['filename']) > 40 else record['filename']
            env = record['env'][:7] + "..." if len(record['env']) > 10 else record['env']
            tags = record['tags'][:17] + "..." if len(record['tags']) > 20 else record['tags']
            print(f"{sha:<12} {filename:<40} {env:<10} {tags:<20}")

        if len(csv_data) > 5:
            print(f"... è¿˜æœ‰ {len(csv_data) - 5} æ¡è®°å½•")

        print("-" * 80)

    def run(self, dry_run=False, force=False, no_backup=False):
        """æ‰§è¡Œæ‰¹é‡æ›´æ–°æµç¨‹"""
        print("=" * 80)
        print("æ‰¹é‡æ›´æ–°æ¨¡ç»„æ•°æ®åº“å·¥å…·")
        print("=" * 80)

        # æ£€æŸ¥æ–‡ä»¶
        if not os.path.exists(self.db_path):
            print(f"âœ— æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return False

        if not os.path.exists(self.csv_path):
            print(f"âœ— CSV æ–‡ä»¶ä¸å­˜åœ¨: {self.csv_path}")
            return False

        # åˆå§‹åŒ–
        if not self.initialize():
            return False

        # è¯»å– CSV æ•°æ®
        print("\næ­£åœ¨è¯»å– CSV æ–‡ä»¶...")
        csv_data = self.read_csv_data()
        if not csv_data:
            print("âœ— æ— æ³•è¯»å– CSV æ•°æ®æˆ– CSV æ–‡ä»¶ä¸ºç©º")
            return False

        # æ˜¾ç¤ºé¢„è§ˆ
        self.show_preview(csv_data)

        # ç¡®è®¤æ‰§è¡Œ
        if not dry_run and not force:
            print(f"\nå‡†å¤‡æ›´æ–° {len(csv_data)} æ¡è®°å½•")
            confirm = input("ç¡®è®¤æ‰§è¡Œå—? (è¾“å…¥ 'yes' ç¡®è®¤): ")
            if confirm.lower() != 'yes':
                print("ğŸš« æ“ä½œå–æ¶ˆ")
                return False

        # å¤‡ä»½æ•°æ®åº“
        if not dry_run and not no_backup:
            print("\næ­£åœ¨å¤‡ä»½æ•°æ®åº“...")
            self.backup_database()

        # æ‰§è¡Œæ‰¹é‡æ›´æ–°
        self.batch_update(csv_data, dry_run)

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()

        # ä¿å­˜é”™è¯¯è®°å½•
        if self.error_records:
            self.save_error_records()

        return True


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡æ›´æ–°æ¨¡ç»„æ•°æ®åº“ä¿¡æ¯',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                          # ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼Œäº¤äº’å¼æ‰§è¡Œ
  %(prog)s --dry-run                # å¹²è¿è¡Œï¼ŒæŸ¥çœ‹å°†è¦æ›´æ–°çš„å†…å®¹
  %(prog)s --force                  # è·³è¿‡ç¡®è®¤ç›´æ¥æ‰§è¡Œ
  %(prog)s --csv custom.csv         # æŒ‡å®šè‡ªå®šä¹‰ CSV æ–‡ä»¶
  %(prog)s --db custom.db           # æŒ‡å®šè‡ªå®šä¹‰æ•°æ®åº“æ–‡ä»¶
        """
    )

    parser.add_argument(
        '--csv',
        default='../.claude/skills/search-mods-info/configs/updated_info.csv',
        help='CSV æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ../.claude/skills/search-mods-info/configs/updated_info.csv)'
    )

    parser.add_argument(
        '--db',
        default='../docs/mods_metadata.db',
        help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ../docs/mods_metadata.db)'
    )

    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='å¹²è¿è¡Œæ¨¡å¼ï¼Œåªæ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¸å®é™…æ›´æ–°æ•°æ®åº“'
    )

    parser.add_argument(
        '--force',
        action='store_true',
        help='è·³è¿‡ç¡®è®¤æç¤ºï¼Œç›´æ¥æ‰§è¡Œ'
    )

    parser.add_argument(
        '--no-backup',
        action='store_true',
        help='è·³è¿‡æ•°æ®åº“å¤‡ä»½ï¼ˆä¸æ¨èï¼‰'
    )

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    # åˆ›å»ºæ‰¹é‡æ›´æ–°ç®¡ç†å™¨
    manager = BatchUpdateManager(
        db_path=os.path.normpath(os.path.join(script_dir, args.db)),
        csv_path=os.path.normpath(os.path.join(script_dir, args.csv))
    )

    # æ‰§è¡Œæ‰¹é‡æ›´æ–°
    success = manager.run(
        dry_run=args.dry_run,
        force=args.force,
        no_backup=args.no_backup
    )

    if not success:
        sys.exit(1)


if __name__ == "__main__":
    main()